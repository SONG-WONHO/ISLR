{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ISLR] Chapter 02 - An Overview of Statistical Learning\n",
    "\n",
    "* ISLR 책을 공부하며 가벼운 내용 소개, 원래 알고 있던 내용을 함께 정리합니다.\n",
    "* ISLR 책에 대한 원서는 [여기](http://www-bcf.usc.edu/~gareth/ISL/)에서 확인할 수 있습니다.\n",
    "* ISLR 책에 대한 참고 블로그는 [Go`s Blog](https://godongyoung.github.io/category/ML.html)를 참고했습니다.\n",
    "* 코드 구현은 [밑바닥부터 시작하는 데이터 과학](https://book.naver.com/bookdb/book_detail.nhn?bid=10652749) 이 책을 참고했습니다.\n",
    "* 오타나 틀린 내용, 토의할 내용은 언제나 이슈로 등록해주세요.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "    2.1 What Is Statistical Learning?\n",
    "        2.1.1 Why Estimate f?\n",
    "        2.1.2 How Do We Estimate f?\n",
    "        2.1.3 The Trade-Off Between Prediction Accuracy and Model Interpretability\n",
    "        2.1.4 Supervised Versus Unsupervised Learning\n",
    "        2.1.5 Regression Versus Classification Problems\n",
    "        \n",
    "    2.2 Assessing Model Accuracy \n",
    "        2.2.1 Measuring the Quality of Fit\n",
    "        2.2.2 The Bias-Variance Trade-Off\n",
    "        2.2.3 The Classification Setting\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 통계적 학습이란 무엇인가?\n",
    "---\n",
    "\n",
    "통계적 학습의 최고 목표는 x와 y가 어떤 관계가 있을 것이라고 가정하고 이를 밝히는 것이다. 좀 더 자세히 말하면 우리에게 $x_1,x_2,..,x_p$ 라는 *input*이 있을 때 $y$라는 *output*이 나오게 되는 관계 즉, **함수**를 찾아내는 것이다. 또는 이를 **패턴**이라고 하기도 한다.\n",
    "\n",
    "\\begin{equation*}\n",
    "y = f(x)\n",
    "\\end{equation*}\n",
    "\n",
    "예를 들어, 제품을 판매하는 한 회사에서 Tv, Radio, Newspaper 광고 지출액과 제품의 판매량의 관계를 알고 싶다고 하자. 이때 우리는 통계적 학습을 적용해볼 수 있을 것이다.\n",
    "\n",
    "이때, x와 y를 지칭하는 용어는 여러가지 있다. x를 **input, predictors, independent variables(독립변수), features**라고 지칭하기도 하고, y를 **output, response, depedent variable(종속변수), target, label**라고 지칭하기도 한다. 경험적으로 통계에선 독립변수, 종속변수 용어를 주로 사용하고 ML쪽에선 Feature, label, target 용어를 주로 사용하는 것 같다.\n",
    "\n",
    "우리는 이 세상에 존재하는 가장 완벽한 함수 $f$를 찾기를 원한다. 하지만 이는 사실상 불가능하다. 이 세상에 있는 모든 데이터를 구할 수 없기 때문이다. 따라서 우리가 정의한 관계, 함수, 패턴에는 항상 오류를 포함하기 마련이다. 이러한 오류를 포함하기 위해 통계학에서는 *error term 'e'를 넣어줘야 한다. 이를 수식으로 표현하면 다음과 같다.\n",
    "\n",
    "\\begin{equation*}\n",
    "y = f(x) + e\n",
    "\\end{equation*}\n",
    "\n",
    "이때 $e$는 우리가 가정한 모델로 절대 줄일 수 없는 오류를 의미한다. 이 역시 모든 데이터를 알 수 없고, 모든 데이터를 알 수 있다고 해도 데이터 속에 완벽한 패턴을 찾아내는 것은 불가능이다.\n",
    "\n",
    "따라서 우리는 **(1) 우리가 관측한 데이터** 속에서 **(2) 적당한 함수공간**을 고려해 함수를 정의하고 선택해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### key sentences\n",
    ">* More generally, suppose that we observe a quantitative response $Y$ and p different predictors, $X_1, X_2, ..., X_p$. We assume that there is some relationship between $Y$ and $X = (X_1, X_2, ..., X_p)$, which can be written in the very general form $y = f(x) + e$.\n",
    "* However, the function $f$ that connects the input variable to the output variable is in general **unknown**. In this situation one must estimate $f$ based on observed points.\n",
    "* In essence, statistical learning refers to a set of approaches for estimating $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Why Estimate f?\n",
    "---\n",
    "\n",
    "우리가 함수 $f$를 추정해야 하는데는 2가지 핵심 이유가 있다. ***f: prediction and inference***\n",
    "\n",
    "#### Prediction (예측)\n",
    "일반적인 ML 문제에서 많이 다루는 문제이다. Kaggle 이나 많은 빅데이터 컴피티션을 보면 주어진 데이터에 기반해 새로운 데이터가 등장했을 때 어떤 값을 가질 지 예측하는 문제가 정말 많다. 주어진 데이터에 기반해 적당한 함수공간 속 함수 $\\hat{f}$을 찾아낸다. 이때 추정된 함수에 의해 새로운 데이터 포인트가 어떤 값을 가질 지 예측할 수 있다.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y} = \\hat{f}(x)\n",
    "\\end{equation*}\n",
    "\n",
    "참고로 $f$는 가장 완벽한 함수(모든 데이터가 주어지고, 어떤 함수공간인지도 알 때), $\\hat{f}$은 특정 함수공간 속에서 주어진 데이터를 기반으로 추정한 함수이다. $\\hat{f}$이 특정 함수공간 속 주어진 데이터를 가장 잘 설명할 수도 있고, 아닐수도 있다.\n",
    "\n",
    "$\\hat{y}$에 대한 오류, 즉 함수가 잘못 추정됐을 것이라는 지표는 ***reducible error***와 ***irreducible error***를 통해 확인할 수 있다. 일반적으로 추정된 함수 $\\hat{f}$은 주어진 조건에서 데이터를 가장 잘 설명하는 패턴, 함수가 아닐 수 있다. 이런 오류가 **reducible error**이다. 반면, 앞서 설명했던 것처럼 모든 데이터 포인트를 알 지 못하고, 함수공간 채택의 한계가 있기 때문에 발생하는 오류가 있다. 이런 오류는 **irreducible error**이다. 이때 중요한 것이 **irreducible error**는 해당 함수에서 발생할 수 있는 어떤 **속성**같은 것이다. 즉, 해당 함수에서 줄일 수 없는 오류라는 것이지, 결국 우리가 데이터를 더 모으고 더 좋은 함수를 찾아내면 결국 이는 줄일 수 있다. 오해하면 안 될것이 우리 관점에서 줄일 수 없는 오류가 아닌 해당 함수가 갖고 있는 특성의 관점에서 줄일 수 없는 오류라는 것이다!\n",
    "\n",
    "이를 수식으로 표현하면 다음과 같다.\n",
    "\n",
    "\\begin{equation*}\n",
    "E(Y-\\hat{Y})^2 = E[f(X) + e - \\hat{f}(X)]^2 = [f(X) - \\hat{f}(X)]^2 + Var(e)\n",
    "\\end{equation*}\n",
    "\n",
    "이때 $[f(X) - \\hat{f}(X)]^2$가 **reducible error**고 $Var(e)$가 **irreducible error**이다. 이 책에서는 어떻게 **reducible error**를 줄일 수 있는 방법에 집중한다.\n",
    "\n",
    "#### Inference (추론)\n",
    "ML쪽에서는 주로 다루지 않는 문제이다. 하지만, 국내 많은 빅데이터 컴피티션(L point, Big contest) 등에선 예측에 더불어 추론 역시 요구한다.\n",
    "우리는 종종 $X_1, X_2, ..., X_p$중 어떤 인자가 $Y$에 영향을 미쳤는 지 궁금해한다. 이 책에선 3가지 주요 관점으로 추론 문제를 다루었다.\n",
    "\n",
    "* 어떤 독립변수가 종속변수와 관계돼 있을까(Feature Selection 등)?\n",
    "* 독립변수와 종속변수사이에 어떤 관계가 있을까(인과관계 등)?\n",
    "* 독립변수와 종속변수의 관계를 선형 방정식 또는 더 복잡한 함수를 통해 적절히 표현할 수 있는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key sentences\n",
    ">* The accuracy of $\\hat{y}$ as a prediction for $y$ depends on two quantities, which we will call the reducible error and the irreducible error.\n",
    "* Why is the irreducible error larger than zero? The quantity $e$ my contain unmeasured variables that are useful in predicting $Y$: since we don`t measure them, $f$ cannot use them for its prediction.\n",
    "* We are often interested in understanding the way that $Y$ is affected as $X_1, X_2, ..., X_p$ change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 How Do We Estimate f?\n",
    "---\n",
    "그럼 어떻게 **reducible error**를 최소화 한 함수를 추정할 수 있을까?\n",
    "\n",
    "만약, 다음 수식이 이해가 된다면, 어떻게 $f$를 추정할 수 있는 지 이미 알고 있는 것이다.\n",
    "\n",
    "$min_{f \\subset F} \\frac{1}{\\infty} \\sum_{i=1}^{\\infty} L(\\hat{f}(x^i), y^i) \\rightarrow min_{f \\subset H} \\frac{1}{n} \\sum_{i=1}^{n} L(\\hat{f}(x^i), y^i)$\n",
    "\n",
    "위 식에서 $F$는 전체 함수 공간에서 존재하는 함수, $H$는 축소된 함수 공간에 존재하는 함수, $n$은 데이터 개수, $L$은 손실함수를 의미한다.\n",
    "\n",
    "즉, 우리는 주어진 데이터를 기반으로 함수공간을 축소하고, 손실(오류, 에러)을 최소화 할 수 있는 가장 바람직한 함수를 찾으면 된다. \n",
    "\n",
    "그렇다면 이제 정의할 것은 함수공간과 손실함수이며, 주로 **parametric Methods**와 **non-parametric Methods**로 이를 설명할 수 있다.\n",
    "\n",
    "#### Parametric Methods\n",
    "Parametric 방법은 먼저, **1) 모델을 정의**, **2) 주어진 데이터를 기반으로 모델 피팅**의 과정이다. 모델 피팅을 위해선 손실함수 역시 정의하고 이를 최소화 할 수 있어야 한다(미분가능성, Convex 만족). 즉, $X$와 $Y$ 사이에 어떤 특정한 관계 (대표적으로 선형관계)가 있다고 가정한 뒤, 주어진 데이터를 기반으로 손실 함수를 최소화 할 수 있는 모델의 계수를 추정하는 것이다. \n",
    "\n",
    "이렇게 모델을 먼저 정의하는 특성때문에 **Model-based Approach**라고도 많이 불린다.\n",
    "\n",
    "Parametric 방법은 몇 개의 parameter(계수)만 추정하면 되기 때문에 해당 가정사항 안에서 많은 분석과 예측을 할 수 있다는 강점이 있지만, 가정이 틀렸을 경우 분석 자체가 의미없을 수 있다는 위험성이 존재한다.\n",
    "\n",
    "#### Non-parametric Methods\n",
    "Non-parametric 방법은 $f$에 대한 어떤 가정도 없이 데이터만 보고 데이터의 특성을 잘 나타내는 $f$를 찾는 방법이다. 이 방법은 $f$에 대한 가정이 없기 때문에 $f$를 가정함으로써 발생하는 위험성 자체가 없어진다. 하지만 기본적으로 정말 많은 데이터를 필요로하고, parametric 방법만큼 직관적이고 다양한 분석을 할 수 없다는 것이 약점이 될 수 있다.\n",
    "\n",
    "최근에는 Deep Learning이 Parmetric Methods 면서 함수 가정에 대한 위험성을 전적으로 줄였다고 생각한다. 결국 함수를 활용하지만, 무수한 데이터를 기반으로 함수를 추정해나가니 마치 그 특성이 Non-parametric Methods 같다. Deep Learning은 형태는 Parametric Methods지만, Non-parametric 특성을 띄는 것이 아닐까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key sentences\n",
    ">* Broadly speaking, most statistical learning methods for this task can be characterized as either parametric or non-parametric.\n",
    "* Parametric methods involve a two-step model-based approach. First, we make an assumption about the functional form, or shape, of $f$. After a model selected, we need a procedure that uses the training data to fit or train the model.\n",
    "* Non-parametric methods do not make explicit assumptions about the functional form of f. Instead they seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 The Trade-Off Between Prediction Accuracy and Model Interpretability\n",
    "---\n",
    "이제 예측 정확도와 모델의 설명 가능성의 trade-off에 대해 알아볼 것이다. 우리는 이상적으로 모델을 통해 다양한, 많은 분석을 할 수 있으며, 예측의 정확도 역시 매우 좋은 하나의 함수를 찾기를 원한다. 즉, 앞서 배운 모델의 inference와 prediction 모두 만족하는 함수를 원한다. 하지만, 이 둘은 trade-off 관계에 있다. 즉, 설명하기 쉬운 함수는 예측 정도가 어느정도 떨어지며, 예측 정도가 높은 함수는 설명하기 어려운 경우가 많다. 아래 그림을 보자.\n",
    "\n",
    "![asdasd](https://user-images.githubusercontent.com/31824102/34830228-262b5be2-f6db-11e7-8fa3-7649ef864dd6.PNG)\n",
    "\n",
    "위 그림에서 flexibility는 함수의 유연함 정도로 생각하면 좋다. 예를 들어, 선형 모델의 경우 함수 자체를 1차원 공간으로 제한한다. 이는 매우 유연하지 못하다. 반면, 다항회귀 또는 다중회귀는 선형 모델에 비선형성을 추가한다. 이는 선형모델보다 함수가 유연하다고 할 수 있다. 일반적으로 flexibility는 complexity라는 용어로 사용되기도 한다. 즉, 함수가 복잡하면 복잡할수록 데이터 사이에 복잡한 패턴을 찾아낼 가능성이 높아지고, 이는 더 높은 예측 정도를 나타낼 수 있다(항상 그렇다는 것은 아니다. 가끔 선형 모델이 비선형 모델보다 더 좋은 예측 정도를 나타내기도 함). 반면 복잡하면 복잡할수록 함수를 설명하기 어려워진다. 즉, 위에서 설명한 inference의 목표를 달성하기 어려워진다. 이후 boosting 계열의 알고리즘을 배울텐데 그때 확실히 와닿을 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Supervised, Unsupervised and Semi-Supervised Learning\n",
    "---\n",
    "일반적으로 주어진 데이터에 따라 통계적 학습은 지도학습, 비지도학습, 준지도학습으로 나뉠 수 있다. 많은 컴피티션에서는 거의 지도학습 위주로 ML 문제를 다루며, 준지도학습의 경우 테크닉적인 요소로 많이 활용한다. 하지만 비지도학습, 준지도학습 쪽 연구가 많이 활발한 것으로 알고 있다.\n",
    "\n",
    "#### 지도학습\n",
    "지도학습은 우리에게 주어진 데이터에 $X$와 $Y$ 모두 존재하는 경우이다. 우리는 주어진 데이터 하에서 $X$와 $Y$ 사이에 가장 바람직한 패턴을 찾는 방향으로 우리의 함수를 추정한다.\n",
    "\n",
    "#### 비지도학습\n",
    "비지도학습은 우리에게 주어진 데이터에 $X$만 존재하는 경우이다. 이 경우 관측된 데이터의 $X$만 가지고 주어진 데이터를 설명하려고 많이 노력한다. 예로 클러스터링이 있다.\n",
    "\n",
    "#### 준지도학습\n",
    "준지도학습은 우리에게 주어진 데이터에 $X$와 $Y$의 **일부**만 주어진 경우이다. $Y$를 얻기 어려운 환경, 일반적인 현실세계속 문제가 이런 양상을 뛴다. 최근 이런 문제를 해결하기 위해 매우 다양한 방법이 연구되고 있다. 이 영역은 이 책의 범위를 벗어나기에 따로 설명하지는 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Regression Versus Classification Problems\n",
    "---\n",
    "\n",
    "지도학습 중 $Y$, label, target, independent variables 에 따라 회귀문제인지 분류문제인지 나뉠 수 있다.\n",
    "\n",
    "#### Regression\n",
    "회귀문제의 경우 종속변수가 연속적인 경우를 의미한다. 예를 들어, 아파트 평수, 아파트 위치, 아파트 층수 정보를 주고 아파트 가격을 예측하는 문제는 회귀문제일 수 있다. 왜냐면 아파트 가격이 연속적이기 때문이다. 참고로 이렇게 연속적인 변수를 통틀어 **Quantitative variables, Numerical variables**라고 지칭한다.\n",
    "\n",
    "#### Classification\n",
    "분류문제의 경우 종속변수가 이산적인 경우를 의미한다. 예를 들어, 아파트 평수, 아파트 위치, 아파트 층수 정보를 주고 아파트 등급(A,B,C,D)를 예측하라는 문제는 분류문제일 수 있다. 왜냐면 아파트 등급은 이산적이기 때문이다. 참고로 이렇게 이산적인 변수를 통틀어 **Qualitative variables, Categorical variables**라고 지칭한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
