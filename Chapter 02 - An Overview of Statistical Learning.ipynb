{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ISLR] Chapter 02 - An Overview of Statistical Learning\n",
    "\n",
    "* ISLR 책을 공부하며 가벼운 내용 소개, 원래 알고 있던 내용을 함께 정리합니다.\n",
    "* ISLR 책에 대한 원서는 [여기](http://www-bcf.usc.edu/~gareth/ISL/)에서 확인할 수 있습니다.\n",
    "* ISLR 책에 대한 참고 블로그는 [Go`s Blog](https://godongyoung.github.io/category/ML.html)를 참고했습니다.\n",
    "* 코드 구현은 [밑바닥부터 시작하는 데이터 과학](https://book.naver.com/bookdb/book_detail.nhn?bid=10652749) 이 책을 참고했습니다.\n",
    "* 오타나 틀린 내용, 토의할 내용은 언제나 이슈로 등록해주세요.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "    2.1 What Is Statistical Learning?\n",
    "        2.1.1 Why Estimate f?\n",
    "        2.1.2 How Do We Estimate f?\n",
    "        2.1.3 The Trade-Off Between Prediction Accuracy and Model Interpretability\n",
    "        2.1.4 Supervised Versus Unsupervised Learning\n",
    "        2.1.5 Regression Versus Classification Problems\n",
    "        \n",
    "    2.2 Assessing Model Accuracy \n",
    "        2.2.1 Measuring the Quality of Fit\n",
    "        2.2.2 The Bias-Variance Trade-Off\n",
    "        2.2.3 The Classification Setting\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 통계적 학습이란 무엇인가?\n",
    "---\n",
    "\n",
    "통계적 학습의 최고 목표는 x와 y가 어떤 관계가 있을 것이라고 가정하고 이를 밝히는 것이다. 좀 더 자세히 말하면 우리에게 $x_1,x_2,..,x_p$ 라는 *input*이 있을 때 $y$라는 *output*이 나오게 되는 관계 즉, **함수**를 찾아내는 것이다. 또는 이를 **패턴**이라고 하기도 한다.\n",
    "\n",
    "\\begin{equation*}\n",
    "y = f(x)\n",
    "\\end{equation*}\n",
    "\n",
    "예를 들어, 제품을 판매하는 한 회사에서 Tv, Radio, Newspaper 광고 지출액과 제품의 판매량의 관계를 알고 싶다고 하자. 이때 우리는 통계적 학습을 적용해볼 수 있을 것이다.\n",
    "\n",
    "이때, x와 y를 지칭하는 용어는 여러가지 있다. x를 **input, predictors, independent variables(독립변수), features**라고 지칭하기도 하고, y를 **output, response, depedent variable(종속변수), target, label**라고 지칭하기도 한다. 경험적으로 통계에선 독립변수, 종속변수 용어를 주로 사용하고 ML쪽에선 Feature, label, target 용어를 주로 사용하는 것 같다.\n",
    "\n",
    "우리는 이 세상에 존재하는 가장 완벽한 함수 $f$를 찾기를 원한다. 하지만 이는 사실상 불가능하다. 이 세상에 있는 모든 데이터를 구할 수 없기 때문이다. 따라서 우리가 정의한 관계, 함수, 패턴에는 항상 오류를 포함하기 마련이다. 이러한 오류를 포함하기 위해 통계학에서는 *error term 'e'를 넣어줘야 한다. 이를 수식으로 표현하면 다음과 같다.\n",
    "\n",
    "\\begin{equation*}\n",
    "y = f(x) + e\n",
    "\\end{equation*}\n",
    "\n",
    "이때 $e$는 우리가 가정한 모델로 절대 줄일 수 없는 오류를 의미한다. 이 역시 모든 데이터를 알 수 없고, 모든 데이터를 알 수 있다고 해도 데이터 속에 완벽한 패턴을 찾아내는 것은 불가능이다.\n",
    "\n",
    "따라서 우리는 **(1) 우리가 관측한 데이터** 속에서 **(2) 적당한 함수공간**을 고려해 함수를 정의하고 선택해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### key sentences\n",
    ">* More generally, suppose that we observe a quantitative response $Y$ and p different predictors, $X_1, X_2, ..., X_p$. We assume that there is some relationship between $Y$ and $X = (X_1, X_2, ..., X_p)$, which can be written in the very general form $y = f(x) + e$.\n",
    "* However, the function $f$ that connects the input variable to the output variable is in general **unknown**. In this situation one must estimate $f$ based on observed points.\n",
    "* In essence, statistical learning refers to a set of approaches for estimating $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Why Estimate f?\n",
    "---\n",
    "\n",
    "우리가 함수 $f$를 추정해야 하는데는 2가지 핵심 이유가 있다. ***f: prediction and inference***\n",
    "\n",
    "#### Prediction (예측)\n",
    "일반적인 ML 문제에서 많이 다루는 문제이다. Kaggle 이나 많은 빅데이터 컴피티션을 보면 주어진 데이터에 기반해 새로운 데이터가 등장했을 때 어떤 값을 가질 지 예측하는 문제가 정말 많다. 주어진 데이터에 기반해 적당한 함수공간 속 함수 $\\hat{f}$을 찾아낸다. 이때 추정된 함수에 의해 새로운 데이터 포인트가 어떤 값을 가질 지 예측할 수 있다.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y} = \\hat{f}(x)\n",
    "\\end{equation*}\n",
    "\n",
    "참고로 $f$는 가장 완벽한 함수(모든 데이터가 주어지고, 어떤 함수공간인지도 알 때), $\\hat{f}$은 특정 함수공간 속에서 주어진 데이터를 기반으로 추정한 함수이다. $\\hat{f}$이 특정 함수공간 속 주어진 데이터를 가장 잘 설명할 수도 있고, 아닐수도 있다.\n",
    "\n",
    "$\\hat{y}$에 대한 오류, 즉 함수가 잘못 추정됐을 것이라는 지표는 ***reducible error***와 ***irreducible error***를 통해 확인할 수 있다. 일반적으로 추정된 함수 $\\hat{f}$은 주어진 조건에서 데이터를 가장 잘 설명하는 패턴, 함수가 아닐 수 있다. 이런 오류가 **reducible error**이다. 반면, 앞서 설명했던 것처럼 모든 데이터 포인트를 알 지 못하고, 함수공간 채택의 한계가 있기 때문에 발생하는 오류가 있다. 이런 오류는 **irreducible error**이다. 이때 중요한 것이 **irreducible error**는 해당 함수에서 발생할 수 있는 어떤 **속성**같은 것이다. 즉, 해당 함수에서 줄일 수 없는 오류라는 것이지, 결국 우리가 데이터를 더 모으고 더 좋은 함수를 찾아내면 결국 이는 줄일 수 있다. 오해하면 안 될것이 우리 관점에서 줄일 수 없는 오류가 아닌 해당 함수가 갖고 있는 특성의 관점에서 줄일 수 없는 오류라는 것이다!\n",
    "\n",
    "이를 수식으로 표현하면 다음과 같다.\n",
    "\n",
    "\\begin{equation*}\n",
    "E(Y-\\hat{Y})^2 = E[f(X) + e - \\hat{f}(X)]^2 = [f(X) - \\hat{f}(X)]^2 + Var(e)\n",
    "\\end{equation*}\n",
    "\n",
    "이때 $[f(X) - \\hat{f}(X)]^2$가 **reducible error**고 $Var(e)$가 **irreducible error**이다. 이 책에서는 어떻게 **reducible error**를 줄일 수 있는 방법에 집중한다.\n",
    "\n",
    "#### Inference (추론)\n",
    "ML쪽에서는 주로 다루지 않는 문제이다. 하지만, 국내 많은 빅데이터 컴피티션(L point, Big contest) 등에선 예측에 더불어 추론 역시 요구한다.\n",
    "우리는 종종 $X_1, X_2, ..., X_p$중 어떤 인자가 $Y$에 영향을 미쳤는 지 궁금해한다. 이 책에선 3가지 주요 관점으로 추론 문제를 다루었다.\n",
    "\n",
    "* 어떤 독립변수가 종속변수와 관계돼 있을까(Feature Selection 등)?\n",
    "* 독립변수와 종속변수사이에 어떤 관계가 있을까(인과관계 등)?\n",
    "* 독립변수와 종속변수의 관계를 선형 방정식 또는 더 복잡한 함수를 통해 적절히 표현할 수 있는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key sentences\n",
    ">* The accuracy of $\\hat{y}$ as a prediction for $y$ depends on two quantities, which we will call the reducible error and the irreducible error.\n",
    "* Why is the irreducible error larger than zero? The quantity $e$ my contain unmeasured variables that are useful in predicting $Y$: since we don`t measure them, $f$ cannot use them for its prediction.\n",
    "* We are often interested in understanding the way that $Y$ is affected as $X_1, X_2, ..., X_p$ change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 How Do We Estimate f?\n",
    "---\n",
    "그럼 어떻게 **reducible error**를 최소화 한 함수를 추정할 수 있을까?\n",
    "\n",
    "만약, 다음 수식이 이해가 된다면, 어떻게 $f$를 추정할 수 있는 지 이미 알고 있는 것이다.\n",
    "\n",
    "$argmin_{f \\subset F} \\frac{1}{\\infty} \\sum_{i=1}^{\\infty} L(\\hat{f}(x^i), y^i) \\rightarrow argmin_{f \\subset H} \\frac{1}{n} \\sum_{i=1}^{n} L(\\hat{f}(x^i), y^i)$\n",
    "\n",
    "위 식에서 $F$는 전체 함수 공간에서 존재하는 함수, $H$는 축소된 함수 공간에 존재하는 함수, $n$은 데이터 개수, $L$은 손실함수를 의미한다.\n",
    "\n",
    "즉, 우리는 주어진 데이터를 기반으로 함수공간을 축소하고, 손실(오류, 에러)을 최소화 할 수 있는 가장 바람직한 함수를 찾으면 된다. \n",
    "\n",
    "그렇다면 이제 정의할 것은 함수공간과 손실함수이며, 주로 **parametric Methods**와 **non-parametric Methods**로 이를 설명할 수 있다.\n",
    "\n",
    "#### Parametric Methods\n",
    "Parametric 방법은 먼저, **1) 모델을 정의**, **2) 주어진 데이터를 기반으로 모델 피팅**의 과정이다. 모델 피팅을 위해선 손실함수 역시 정의하고 이를 최소화 할 수 있어야 한다(미분가능성, Convex 만족). 즉, $X$와 $Y$ 사이에 어떤 특정한 관계 (대표적으로 선형관계)가 있다고 가정한 뒤, 주어진 데이터를 기반으로 손실 함수를 최소화 할 수 있는 모델의 계수를 추정하는 것이다. \n",
    "\n",
    "이렇게 모델을 먼저 정의하는 특성때문에 **Model-based Approach**라고도 많이 불린다.\n",
    "\n",
    "Parametric 방법은 몇 개의 parameter(계수)만 추정하면 되기 때문에 해당 가정사항 안에서 많은 분석과 예측을 할 수 있다는 강점이 있지만, 가정이 틀렸을 경우 분석 자체가 의미없을 수 있다는 위험성이 존재한다.\n",
    "\n",
    "#### Non-parametric Methods\n",
    "Non-parametric 방법은 $f$에 대한 어떤 가정도 없이 데이터만 보고 데이터의 특성을 잘 나타내는 $f$를 찾는 방법이다. 이 방법은 $f$에 대한 가정이 없기 때문에 $f$를 가정함으로써 발생하는 위험성 자체가 없어진다. 하지만 기본적으로 정말 많은 데이터를 필요로하고, parametric 방법만큼 직관적이고 다양한 분석을 할 수 없다는 것이 약점이 될 수 있다.\n",
    "\n",
    "최근에는 Deep Learning이 Parmetric Methods 면서 함수 가정에 대한 위험성을 전적으로 줄였다고 생각한다. 결국 함수를 활용하지만, 무수한 데이터를 기반으로 함수를 추정해나가니 마치 그 특성이 Non-parametric Methods 같다. Deep Learning은 형태는 Parametric Methods지만, Non-parametric 특성을 띄는 것이 아닐까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key sentences\n",
    ">* Broadly speaking, most statistical learning methods for this task can be characterized as either parametric or non-parametric.\n",
    "* Parametric methods involve a two-step model-based approach. First, we make an assumption about the functional form, or shape, of $f$. After a model selected, we need a procedure that uses the training data to fit or train the model.\n",
    "* Non-parametric methods do not make explicit assumptions about the functional form of f. Instead they seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 The Trade-Off Between Prediction Accuracy and Model Interpretability\n",
    "---\n",
    "이제 예측 정확도와 모델의 설명 가능성의 trade-off에 대해 알아볼 것이다. 우리는 이상적으로 모델을 통해 다양한, 많은 분석을 할 수 있으며, 예측의 정확도 역시 매우 좋은 하나의 함수를 찾기를 원한다. 즉, 앞서 배운 모델의 inference와 prediction 모두 만족하는 함수를 원한다. 하지만, 이 둘은 trade-off 관계에 있다. 즉, 설명하기 쉬운 함수는 예측 정도가 어느정도 떨어지며, 예측 정도가 높은 함수는 설명하기 어려운 경우가 많다. 아래 그림을 보자.\n",
    "\n",
    "![그림](https://user-images.githubusercontent.com/31824102/34830228-262b5be2-f6db-11e7-8fa3-7649ef864dd6.PNG)\n",
    "\n",
    "위 그림에서 flexibility는 함수의 유연함 정도로 생각하면 좋다. 예를 들어, 선형 모델의 경우 함수 자체를 1차원 공간으로 제한한다. 이는 매우 유연하지 못하다. 반면, 다항회귀 또는 다중회귀는 선형 모델에 비선형성을 추가한다. 이는 선형모델보다 함수가 유연하다고 할 수 있다. 일반적으로 flexibility는 complexity라는 용어로 사용되기도 한다. 즉, 함수가 복잡하면 복잡할수록 데이터 사이에 복잡한 패턴을 찾아낼 가능성이 높아지고, 이는 더 높은 예측 정도를 나타낼 수 있다(항상 그렇다는 것은 아니다. 가끔 선형 모델이 비선형 모델보다 더 좋은 예측 정도를 나타내기도 함). 반면 복잡하면 복잡할수록 함수를 설명하기 어려워진다. 즉, 위에서 설명한 inference의 목표를 달성하기 어려워진다. 이후 boosting 계열의 알고리즘을 배울텐데 그때 확실히 와닿을 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Supervised, Unsupervised and Semi-Supervised Learning\n",
    "---\n",
    "일반적으로 주어진 데이터에 따라 통계적 학습은 지도학습, 비지도학습, 준지도학습으로 나뉠 수 있다. 많은 컴피티션에서는 거의 지도학습 위주로 ML 문제를 다루며, 준지도학습의 경우 테크닉적인 요소로 많이 활용한다. 하지만 비지도학습, 준지도학습 쪽 연구가 많이 활발한 것으로 알고 있다.\n",
    "\n",
    "#### 지도학습\n",
    "지도학습은 우리에게 주어진 데이터에 $X$와 $Y$ 모두 존재하는 경우이다. 우리는 주어진 데이터 하에서 $X$와 $Y$ 사이에 가장 바람직한 패턴을 찾는 방향으로 우리의 함수를 추정한다.\n",
    "\n",
    "#### 비지도학습\n",
    "비지도학습은 우리에게 주어진 데이터에 $X$만 존재하는 경우이다. 이 경우 관측된 데이터의 $X$만 가지고 주어진 데이터를 설명하려고 많이 노력한다. 예로 클러스터링이 있다.\n",
    "\n",
    "#### 준지도학습\n",
    "준지도학습은 우리에게 주어진 데이터에 $X$와 $Y$의 **일부**만 주어진 경우이다. $Y$를 얻기 어려운 환경, 일반적인 현실세계속 문제가 이런 양상을 뛴다. 최근 이런 문제를 해결하기 위해 매우 다양한 방법이 연구되고 있다. 이 영역은 이 책의 범위를 벗어나기에 따로 설명하지는 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Regression Versus Classification Problems\n",
    "---\n",
    "\n",
    "지도학습 중 $Y$, label, target, independent variables 에 따라 회귀문제인지 분류문제인지 나뉠 수 있다.\n",
    "\n",
    "#### Regression\n",
    "회귀문제의 경우 종속변수가 연속적인 경우를 의미한다. 예를 들어, 아파트 평수, 아파트 위치, 아파트 층수 정보를 주고 아파트 가격을 예측하는 문제는 회귀문제일 수 있다. 왜냐면 아파트 가격이 연속적이기 때문이다. 참고로 이렇게 연속적인 변수를 통틀어 **Quantitative variables, Numerical variables**라고 지칭한다.\n",
    "\n",
    "#### Classification\n",
    "분류문제의 경우 종속변수가 이산적인 경우를 의미한다. 예를 들어, 아파트 평수, 아파트 위치, 아파트 층수 정보를 주고 아파트 등급(A,B,C,D)를 예측하라는 문제는 분류문제일 수 있다. 왜냐면 아파트 등급은 이산적이기 때문이다. 참고로 이렇게 이산적인 변수를 통틀어 **Qualitative variables, Categorical variables**라고 지칭한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 모델 평가하기\n",
    "---\n",
    "\n",
    "모델, 함수, 패턴, 머신 다 일맥상 통하는 말이다. 모델을 평가한다는 말은 주어진 데이터에 기반해 추정한 우리의 함수를 평가한다는 말이다.\n",
    "\n",
    "**그렇다면 평가를 왜 해야할까?** 당연히 우리는 우리가 추정한 함수가 얼마나 잘 추정됐는 지, 우리의 데이터를 얼마나 잘 설명하는 지, 이상적인 함수와 얼마나 가까운 지 등을 알고싶기 때문이다. 평가를 했을 때, 좋지 않다면, 실제 써먹기 어렵다는 말이고, 결국 더 좋은 함수를 다시 추정하기 위해 여러 전략을 수립해야 한다. 이런 의미에서 모델 평가, 함수 평가, 패턴 평가 등은 정말 중요하다.\n",
    "\n",
    "**그렇다면 모델을 어떻게 평가할 수 있을까?** 이 문제는 어떤 평가 지표를 사용하는 지에 따라 천차만별이다. 이 세상에는 정말 다양한 평가지표들이 있다. 예를 들어, 우리가 대학에 입학한다고 했을 때, 학생을 평가하는 요소는 정말 다양하다. 수능성적부터, 내신, 수상경력, 독서활동 등 학생을 평가할 수 있는 지표는 정말 다양하다. 이처럼 우리의 함수, 모델을 평가하는 지표 역시 $MSE$, $RMSE$, $R^2$, $MAP$, $F_1 score$, $AUC$ 등 다양한 지표가 존재한다. 케글 컴피티션 같은 경우 단 하나의 지표가 존재하는 것이 아닌, 컴피티션 주최측에서 원하는 지표가 있기에 그 지표를 통해 우리의 모델을 평가하면된다. 이 책에서는 MSE 지표를 이 장에서 주로 설명하고 있다.\n",
    "\n",
    "마지막으로 모델 평가에 있어서 정말 중요한 한 가지 사실이 있다. 예측 문제에서 우리가 모델을 추정하는 가장 핵심적인 목표는 무엇일까? 주어진 데이터에 기반해 모델, 함수를 추정함으로써 보이지 않는 데이터, 앞으로 발생할 데이터, 또는 과거에 누락된 데이터를 예측하는 것이다. 이때, 우리에게 주어진 데이터를 ***train data***, 우리에게 주어지지 않은 데이터를 ***test data***라고 한다. 우리는 결국 ***train data***에 좋은 점수를 내는 함수가 아닌, ***test data***에 좋은 점수를 내는 함수를 추정하고 채택하고자 한다. 이 관점에서 우리는 ***train data***를 ***train data***와 ***validation data***로 나눠야하고, ***train data***에 대한 점수가 아닌 ***validation data***에 대한 점수로 우리의 모델을 채택해야만 한다. 이 부분에 대한 내용은 5장에서 상세히 다룬다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Measuring the Quality of Fit\n",
    "---\n",
    "\n",
    "일반적으로 모델을 평가할 때 사용될 수 있는 지표는 정말 많다. 회귀 문제의 경우 $MSE$라는 지표가 주로 사용되며 이번 장에서 $MSE$에 대해 알아볼 것이다. $MSE$는 ***Mean Squared Error***로 에러 제곱의 평균이라는 의미를 갖고 있다. 아래 수식을 보자.\n",
    "\n",
    "\\begin{equation*}\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{f}(x_i))^2\n",
    "\\end{equation*}\n",
    "\n",
    "$(x_i, y_i)$는 우리가 갖고 있는 $n$개의 데이터 중 $i$번째 데이터를 의미한다. $\\hat{f}$은 주어진 데이터를 토대로 추정한 함수를 의미한다. \n",
    "\n",
    "즉, **((예측한 $y$값과 실제 $y$값의 차)의 제곱)의 평균**을 의미한다.\n",
    "\n",
    "아래 그림을 보면 빨간색 포인트가 우리가 관측한 데이터, 파란색 선이 주어진 데이터에 기반해 우리가 추정한 함수, 회색 선이 실제값과 예측값의 차, 잔차를 의미한다.\n",
    "\n",
    "\n",
    "![그림](https://user-images.githubusercontent.com/31824102/34830490-ea5cece2-f6db-11e7-9234-4fd206e010d1.PNG)\n",
    "\n",
    "낮은 $MSE$는 우리의 함수가 주어진 데이터를 잘 설명하고 있다는 것을 의미한다. 이제부터 주어진 데이터를 ***train data***라고 하겠다. 하지만, 우리의 궁극적인 목표는 주어지지 않은 데이터를 잘 예측하는 것이다. 이제부터 주어지지 않은 데이터를 ***test data***라고 하겠다. 즉, 우리는 **train** $MSE$가 낮은 함수를 선택하는 것이 아닌, **test** $MSE$가 낮은 함수를 선택해야만 한다. 하지만, 우리에게 ***test data***는 주어지지 않는다. ***test data***란 말 그대로 주어지지 않은 데이터, 앞으로 일어날 데이터, 과거에 누락된 데이터 등을 의미하기 때문이다. 여기서 한 가지 문제가 생긴다. 우리는 **test** $MSE$를 통해 우리의 모델을 선택해야 되지만, ***test data***가 주어지지 않는다는 역설적인 상황이 생기게 된다. 이 문제를 해결하기 위해 다양한 방법들이 5장에 소개될 것이다. 약간의 힌트를 주자면, ***train data***에 약간의 조작을 가하면 마치 ***test data***가 주어진 것과 같은 효과를 줄 수도 있다!\n",
    "\n",
    "여기서 중요한 것이 절대 **train** $MSE$를 모델 선택의 지표로 활용하면 안된다는 것이다. 아래 그래프를 보자.\n",
    "\n",
    "![그림](https://user-images.githubusercontent.com/31824102/34830504-fa8ede2c-f6db-11e7-90fc-ac67cef60fe0.PNG)\n",
    "\n",
    "왼쪽 그래프는 실제 데이터 포인트와 추정된 여러 함수를 나타낸다. 겨자색 함수의 경우 복잡도가 낮고, 초록색 함수의 경우 복잡도가 매우 높다. 가볍게 함수 공간의 개념으로 생각하면 겨자색 함수는 제약이 많이 가해진 함수일 것이고(1차 공간), 초록색 함수는 상대적으로 제약이 적은 함수(2차, 3차, 4차 ... 공간)일 것이다. 오른쪽 그래프는 함수의 복잡도 별 **train** $MSE$와 **test** $MSE$를 나타낸다. 빨간색 그래프가 **test** $MSE$고 회색 그래프가 **train** $MSE$이다. \n",
    "\n",
    "자 이 상황에서 어떤 함수가 가장 잘 추정됐다고 볼 수 있을까? 바로 파란색 함수이다. 파란색 함수는 **test** $MSE$가 가장 낮기에 보이지 않는 데이터를 가장 잘 설명할 확률이 가장 높다.\n",
    "\n",
    "일반적인 용어로 초록색 함수의 경우 ***overfitting(과적합)*** 됐다고 많이 표현하며, 겨자색 함수의 경우 ***underfitting(과소적합)*** 됐다고 주로 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key sentences\n",
    "\n",
    ">* In the regression setting, the most commonly-used measure is the ***mean squared error(MSE)***.\n",
    "* Rather, we are interested in the accuracy of the predictions that we obtain when we apply our method to previously unseen test data.\n",
    "* We want to choose the method that gives the lowest ***test MSE***, as opposed to the lowest training MSE.\n",
    "* When a given method yields a small training MSE but a large test MSE, we are said to be **overfitting** the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 The Bias-Variance Trade-Off\n",
    "---\n",
    "Bias-Variance Trade-Off, ML에 대해 한번쯤 공부해봤다면, 항상 만나는 주제이다. 그만큼 ML에서 이 문제에 대해 다루는 것이 중요하고, 또 ML를 연구하는 사람마다 이 문제에 대해 다양한 견해를 갖고 있다. 당장 구글에 Bias Variance Trade-Off만 검색해봐도, 정말 많은 블로그가 이 주제에 대해 다루고 있으며, 또 많은 ML 강의를 들어봐도 정말 다양한 견해로 많은 강의자들이 이 문제를 다루고 있다. 또 이 키워드로 검색을 해보면 항상 양궁 과녁처럼 생긴 예제와 함께 설명하는 그림이 정말 많이 나온다. 다만, ML에서의 Bias-Variance 문제와 양궁의 그림과 연관지어 이해하기 많이 어려운 부분이 있으니 일단, ML에서의 Bias-Varance 문제에 대해 다룬 뒤, 양궁 그림과 연관지어 설명하겠다.\n",
    "\n",
    "#### Variance\n",
    "Variance는 **train data**가 바뀌었을 때, 우리가 추정한 함수 $\\hat{f}$이 바뀌는 정도를 의미한다. 만약 **train data**가 바뀌었을 때, $\\hat{f}$가 많이 바뀐다면, 해당 함수의 Variance는 크다고 볼 수 있고, $\\hat{f}$이 많이 바뀌지 않는다면, 해당 함수의 Variance는 작다고 볼 수 있다. 여기서 정말 중요한 점이, Variance는 해당 함수에 속해있는 어떤 **특성**과도 같은 것이다. 즉, 우리가 해당 함수를 설명하기 위해 만들어낸 어떤 개념과도 같은 것이다. 함수가 먼저 존재하고, 함수를 잘 설명하기 위해 Variance 라는 속성을 부여했다의 개념으로 생각해야 한다. 일반적으로 함수의 Flexibility가 크면 클수록 함수의 Variance 정도는 크다고 알려져 있다. 예를 들어, **train data**가 바뀌면 바뀔수록 다양한 데이터 포인트가 포함될 것이고, Flexibility가 큰 함수의 경우 이런 다양한 포인트 역시 포함하는 방향으로 추정될 것이라고 생각할 수 있다. 즉, Flexibility가 크면 클수록 다양한 데이터 포인트를 포함하게 될 것이고, 이는 매 학습마다 다양한 함수가 존재한다는 것으로 생각할 수 있다. 다양한 함수가 존재한다는 것은 Variance가 크다는 것을 의미한다.\n",
    "\n",
    "#### Bias\n",
    "Bias는 간단한 함수 또는 전체 데이터의 일부로 매우 복잡한 실세계의 문제를 해결하고자 할 때, 발생할 수 있는 오류를 의미한다. 우리는 함수를 추정할 때, 함수를 특정 함수 공간속에 존재하는 함수로 가정한다. 이렇게 가정된 함수로 주어진 데이터 사이에 어떤 패턴을 찾아내고자 한다. 이때 함수를 가정된 함수공간 내에 아무리 잘 적합한다고 하더라도, 가정때문에 발생하는 필연적인 오류가 존재한다. 이때 이 오류를 Bias라고 한다. 또한 우리는 전체 데이터의 일부만을 수집할 수 있다. 즉 수집된 일부 데이터가 전체와 다름에서 발생하는 필연적인 오류가 있고, 이 오류를 Bias라고 한다. 여기서 중요한 점이, Variance와 마찬가지로 Bias 역시 해당 함수에 속해있는 어떤 **특성**과도 같은 것이다. 즉, 함수를 잘 설명하기 위해서 Bias라는 개념을 만들어 낸 것이다. 일반적으로 함수의 Complexity가 크면 클수록 Bias는 줄어들 것이다. Complexity가 크다는 말의 의미는 더 큰 함수공간 속 함수를 채택한다는 의미이고, 함수가 복잡하면 복잡할 수록, 현실세계에 존재하는 복잡한 패턴을 찾아낼 가능성이 더 크다.\n",
    "\n",
    "#### Bias-Variance Trade-Off\n",
    "이처럼 일반적으로 Bias가 크면 Variance가 작고, Bias가 작으면 Variance가 큰 경우가 많다. 이 점때문에 Trade-Off라는 용어를 사용하는 것 같다. 하지만, Bias와 Variance는 완벽한 Trade-Off 관계가 아니다. Variance가 크면서 Bias가 클 수도 있다. 예를 들어, 주어진 데이터의 패턴이 100차원에 존재하는 패턴이라고 가정해보자. 또한 주어진 데이터가 100차원의 패턴을 찾을 만큼 충분하지 않다고 가정해보자. 이런 상황에 우리가 40차원의 함수를 채택하면 Variance도 높고 Bias도 높은 함수가 될 수 있다. 이처럼 항상 Bias와 Variance가 Trade-Off 관계에 있다고 생각하면 안된다.\n",
    "\n",
    "#### 정리\n",
    "![양궁](https://modulabs-biomedical.github.io/assets/images/posts/2018-01-25-Bias_vs_Variance/3.jpg)\n",
    "\n",
    "위 그림은 Variance와 Bias를 설명할 때 자주 등장하는 그림이다. 앞서 설명을 이해했다면 위 그림 자체를 이해하는 것은 어렵지 않다. 이제 ML에서의 Bias-Variance를 위 그림에 연관지어 설명해보겠다. 먼저 파란색 점은 ML에서의 추정된 함수라고 생각하면 된다. 왼쪽 아래 그림은 Low Variance와 High Bias를 의미한다. 즉, 추정된 함수가 함수공간을 제한해서 발생하는 오류를 포함하지만(파란색 포인트들의 평균), 상대적으로 **train data**에 덜 민감해 변화정도가 작은 함수 집합이라고 생각할 수 있다. 오른쪽 위 그림은 High Variance와 Low Bias를 의미한다. 즉, 추정된 함수가 함수공간을 상대적으로 절 제한했기 때문에 오류 자체는 낮지만(파란색 포인트들의 평균), 상대적으로 **train data**에 많이 민감해 변화정도가 큰 함수 집합이라고 생각할 수 있다. 사실 이 설명은 양궁 그림을 어거지로 설명하다 보니 조금 어색한 감이 있다. 하지만, 책에서 다룬 ML에서의 Bias-Variance 개념만 완벽히 이해한다면, 어떤 블로그 포스팅을 봐도 이해하기 어렵지 않을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B-V 문제에 있어 여러 질문이 나올 수 있는데 그때 그때 떠오르는 것 위주로 작성하겠다.\n",
    "\n",
    "* 1) Variance 크다는 말은 Overfitting 이라는 말과 동치인가? \n",
    "일반적으로 우리는 variance가 크다면 모델이 데이터에 overfitting 돼있다고 알고 있다. 하지만 이는 항상 맞는 말이 아니다. 여러분은 Overfitting의 정의를 무엇이라 생각하는가? 일반적인 대답은 **train data**를 너무 잘 설명해 **test data**에는 설명하지 못하는 상황이다. 여기서 중요한 점은 **test data**를 잘 설명하지 못한다는 것이다. 즉, 우리는 **train data**만 가지고, overfitting 여부를 알 수 없다. 데이터가 주어졌을 때 어떤 함수가 이 데이터를 완벽히 설명한다고 해보자. 그렇다면 overfitting인가? 답은 '모른다'이다. 즉, 우리는 overfitting을 **test data**에 확장해서 생각한다.\n",
    "\n",
    "그렇다면 variance의 정의는 무엇일까? 위에서 배웠듯이 variance는 **train data**에 따라 함수가 바뀌는 정도이다. variance가 크면 **train data**를 잘 설명할 확률이 크다.\n",
    "\n",
    "즉, variance가 크다는 것은 함수에 종속된 특성이다. 반면 overfitting은 **test data**와 관련된 현상이다. 즉, Variance가 크면 Overfitting될 확률이 높다고 하는 것이 맞다고 생각한다. \n",
    "\n",
    "반례로 Variance가 크지만 underfitting 되는 상황이 있을 수 있다. 우리가 수집한 **train data**가 일반적인 상황을 대변하지 못하는 상황에서는 **train data**에 종속된 함수의 특성인 variance가 의미가 없다. 즉, **test cost**가 큰 것이 variance가 커서가 아니라, 애초에 모델이 **test data**를 설명할 수 없는 상황인 것이다.\n",
    "\n",
    "사실 위 가정, 즉 **train data**와 **test data**가 분포가 비슷할 것이다라는 가정은 통계적 학습에 있어서 제일 우선시 되는 가정이다. 또는 **train data**와 **test data**사이에 어떠한 패턴이 존재할 것이라는 것 또한 제일 우선시 되는 가정이다. 위 가정을 만족하지 못하는 상황에서 통계적 학습은 의미가 없다고 생각한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key sentences\n",
    ">* Variance refers to the amount by which $\\hat{f}$ would change if we estimated it using a different training data set.\n",
    "* In general, more flexible statistical methods have higher variance.\n",
    "* Bias refers to the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much simpler model.\n",
    "* Generally, more flexible methods result in less bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 The Classification Setting\n",
    "---\n",
    "이번 장에서는 분류 문제에서 주로 사용하는 지표와 몇몇 분류 알고리즘(모델)에 대해 설명한다. 이 장에서 소개하는 분류 알고리즘으로는 **The Bayes Classifier**와 **K-Nearest Neighbors**를 다루는데, 추후 따로 장을 파 더 깊게 다룰 생각이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리\n",
    "---\n",
    "이번 장에 ML을 공부하면서 정말 중요하다고 느낀 많은 주제를 다루었다. 사실 몇몇 장을 제외하고 이후 장부터는 데이터 특성에 적합한 여러 모델들을 소개하는 수준이다. 이 책의 가장 중요한 핵심은 이 장에 있다고 생각한다. 이 장을 곱씹고 곱씹어 본인 것으로 만들길 바란다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
